version: '3'  # 指定版本

services:
  # --- Auth Service ---
  auth_db:
    image: mysql:8.0
    container_name: auth_mysql_db
    environment:
      MYSQL_ROOT_PASSWORD: your_auth_root_password
      MYSQL_DATABASE: auth_db
      MYSQL_USER: auth_user
      MYSQL_PASSWORD: auth_password
      MYSQL_DEBEZIUM_USER: debezium
      MYSQL_DEBEZIUM_PASSWORD: dbz
    command:
      - --default-authentication-plugin=mysql_native_password
      - --binlog-format=ROW
      - --log-bin=mysql-bin
      - --server-id=1
    # Kind中不直接映射主机端口，通过K8s Service暴露
    # ports:
    #   - "3307:3306"
    volumes:
      # 替换为K8s PVC（后续通过kompose转换时自动生成）
      - auth_mysql_data:/var/lib/mysql
      - ./init_debezium_user.sql:/docker-entrypoint-initdb.d/init_debezium_user.sql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      timeout: 20s
      retries: 10
      interval: 10s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  auth_service:
    build: ./auth_service
    # ports:
    #   - "5000:5000"
    environment:
      DB_HOST: auth_db  # 使用服务名通信（Kind内部DNS支持）
      DB_USER: auth_user
      DB_PASSWORD: auth_password
      DB_NAME: auth_db
    depends_on:
      - auth_db
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # --- Book Management Service (MongoDB) ---
  book_db_mongo:
    build: ./mongo_custom_image
    container_name: book_mongo_db
    environment:
      MONGO_INITDB_ROOT_USERNAME: book_user
      MONGO_INITDB_ROOT_PASSWORD: book_password
      MONGO_INITDB_DATABASE: book_manage_db
    # ports:
    #   - "27017:27017"
    volumes:
      - book_mongo_data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')", "--quiet", "-u", "book_user", "-p", "book_password", "--authenticationDatabase", "admin"]
      interval: 5s
      timeout: 5s
      retries: 10
    command:
      - mongod
      - --replSet
      - dbrs
      - --keyFile
      - /etc/mongo/mongodb_keyfile.txt
      - --bind_ip_all
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  mongo_setup:
    image: mongo:latest
    container_name: mongo_setup
    depends_on:  # 正确格式：键值对（带condition时）
      - book_db_mongo
    command: >
      bash -c "
        mongosh --host book_db_mongo:27017 --username book_user --password book_password --authenticationDatabase admin <<EOF
          rs.initiate({
            _id: 'dbrs',
            members: [ { _id: 0, host: 'book_db_mongo:27017' } ]
          });EOF
      "
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 256M

  book_manage:
    build: ./book_manage
    # ports:
    #   - "5001:5001"
    environment:
      MONGO_HOST: book_db_mongo  # 服务名通信
      MONGO_USER: book_user
      MONGO_PASSWORD: book_password
      MONGO_DB_NAME: book_manage_db
    depends_on:
      - book_db_mongo
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # --- User Engagement Service ---
  user_engagement_db:
    image: mysql:8.0
    container_name: user_engagement_mysql_db
    environment:
      MYSQL_ROOT_PASSWORD: your_engagement_root_password
      MYSQL_DATABASE: book_engagement
      MYSQL_USER: engagement_user
      MYSQL_PASSWORD: engagement_password
      MYSQL_DEBEZIUM_USER: debezium
      MYSQL_DEBEZIUM_PASSWORD: dbz
    command:
      - --default-authentication-plugin=mysql_native_password
      - --binlog-format=ROW
      - --log-bin=mysql-bin
      - --server-id=2
    # ports:
    #   - "3309:3306"
    volumes:
      - user_engagement_mysql_data:/var/lib/mysql
      - ./init_debezium_user_engagement.sql:/docker-entrypoint-initdb.d/init_debezium_user_engagement.sql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      timeout: 20s
      retries: 10
      interval: 10s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  user_engagement_service:
    build: ./user_engagement_service
    container_name: user_engagement_service_app
    # ports:
    #   - "5003:5003"
    environment:
      DATABASE_URL: mysql+pymysql://engagement_user:engagement_password@user_engagement_db:3306/book_engagement
    depends_on:
      - user_engagement_db
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # --- ETL Infrastructure ---
  zookeeper:
    image: 'confluentinc/cp-zookeeper:7.5.3'
    hostname: zookeeper
    container_name: zookeeper
    # ports:
    #   - "22181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD", "sh", "-c", "nc -z localhost 2181 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  kafka:
    image: confluentinc/cp-kafka:7.5.3
    hostname: kafka
    container_name: kafka
    # ports:
    #   - "9092:9092"
    #   - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'  # 服务名通信
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://kafka:9094  # 内部用服务名
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_MESSAGE_MAX_BYTES: 1572864000
      KAFKA_REPLICA_FETCH_MAX_BYTES: 1572864000
      KAFKA_MAX_REQUEST_SIZE: 1572864000
    depends_on:
      - zookeeper
    healthcheck:
      test: ["CMD", "sh", "-c", "kafka-topics --bootstrap-server kafka:29092 --list > /dev/null || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G

  kafka_connect:
    image: confluentinc/cp-kafka-connect:8.0.0
    container_name: kafka_connect
    # ports:
    #   - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:29092  # 服务名通信
      CONNECT_GROUP_ID: connect-cluster-group
      CONNECT_LISTENERS: http://0.0.0.0:8083
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka_connect
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_HEAP_OPTS: "-Xmx2G -Xms2G"
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "true"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "true"
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_PLUGIN_PATH: "/usr/share/confluent-hub-components"
    command:
      - bash
      - -c
      - |
        echo "Waiting for Kafka to be ready..."
        cub kafka-ready -b kafka:29092 1 20
        echo "Installing connectors..."
        confluent-hub install --no-prompt clickhouse/clickhouse-kafka-connect:latest
        confluent-hub install --no-prompt debezium/debezium-connector-mysql:3.1.2
        confluent-hub install --no-prompt debezium/debezium-connector-mongodb:3.1.2
        /etc/confluent/docker/run
    depends_on:
      - kafka
      - auth_db
      - book_db_mongo
      - mongo_setup
      - clickhouse
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 3G
        reservations:
          cpus: '0.5'
          memory: 2G

  # --- Recommendation Service DB ---
  recommendation_db:
    image: mysql:8.0
    container_name: recommendation_mysql_db
    environment:
      MYSQL_ROOT_PASSWORD: your_rec_root_password
      MYSQL_DATABASE: recommendation_db
      MYSQL_USER: rec_user
      MYSQL_PASSWORD: rec_password
    # ports:
    #   - "3308:3306"
    volumes:
      - recommendation_mysql_data:/var/lib/mysql
      - ./init_recommendation_db.sql:/docker-entrypoint-initdb.d/init_recommendation_db.sql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      timeout: 20s
      retries: 10
      interval: 10s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # --- ETL Spark Processor ---
  spark_etl_processor:
    build: ./spark_etl_processor
    container_name: spark_etl_processor
    environment:
      KAFKA_BROKER_URL: kafka:29092
      REC_DB_HOST: recommendation_db
      REC_DB_USER: rec_user
      REC_DB_PASSWORD: rec_password
      REC_DB_NAME: recommendation_db
      CLICKHOUSE_HOST: clickhouse
      CLICKHOUSE_PORT: 8123
    depends_on:  # 移除列表项符号 `-`，直接用键值对
      - kafka
      - recommendation_db
      - clickhouse
    command: /opt/bitnami/spark/bin/spark-submit --master local[*] --driver-memory 2G --executor-memory 2G --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.kafka:kafka-clients:3.4.1,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1,mysql:mysql-connector-java:8.0.28 /app/main.py
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  # --- ClickHouse Service ---
  clickhouse:
    image: clickhouse/clickhouse-server:23.8
    container_name: clickhouse_db
    # ports:
    #   - "8123:8123"
    #   - "9000:9000"
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - clickhouse_logs:/var/log/clickhouse-server
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider 'http://localhost:8123/ping' || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 3G
        reservations:
          cpus: '1.0'
          memory: 2G

  # --- Flink Services ---
  flink-jobmanager:
    build: ./flink_py_image
    container_name: flink-jobmanager
    command: jobmanager
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager  # 服务名通信
        jobmanager.rpc.port: 6123
        rest.address: flink-jobmanager
        rest.port: 8081
        taskmanager.numberOfTaskSlots: 1
        python.executable: /usr/bin/python3
    volumes:
      - ./flink_jobs:/opt/flink/usrlib
    depends_on:
      - kafka
      - redis
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/overview || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  flink-taskmanager:
    build: ./flink_py_image
    container_name: flink-taskmanager
    command: taskmanager
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink-jobmanager  # 服务名通信
        jobmanager.rpc.port: 6123
        taskmanager.numberOfTaskSlots: 1
        python.executable: /usr/bin/python3
    depends_on:
      - flink-jobmanager
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  flink-job-submitter:
    build: ./flink_py_image
    container_name: flink-job-submitter
    command: >
      bash -c "
        echo 'Waiting for Flink JobManager...' &&
        until curl -f http://flink-jobmanager:8081/overview; do
          sleep 5;
        done &&
        echo 'Submitting PyFlink Job...' &&
        /opt/flink/bin/flink run --jarfile /opt/flink/usrlib/jars/flink-sql-connector-kafka-3.0.0-1.17.jar -py /opt/flink/usrlib/scripts/realtime_recommendation_job.py
      "
    volumes:
      - ./flink_jars:/opt/flink/usrlib/jars
      - ./flink_jobs:/opt/flink/usrlib/scripts
    depends_on:
      - flink-jobmanager
    restart: "no"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # --- Redis Service ---
  redis:
    image: redis:6.2-alpine
    container_name: redis_cache
    # ports:
    #   - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # --- Recommendation Services ---
  realtime_recommendation_service:
    build: ./realtime_recommendation_service
    container_name: realtime_recommendation_service
    # ports:
    #   - "5004:5004"
    environment:
      REDIS_HOST: redis  # 服务名通信
      REDIS_PORT: 6379
    depends_on:
      - redis
      - flink-job-submitter
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  offline_recommendation_service:
    build: ./offline_recommendation_service
    container_name: offline_recommendation_service_app
    # ports:
    #   - "5005:5005"
    environment:
      REC_DB_HOST: recommendation_db  # 服务名通信
      REC_DB_USER: rec_user
      REC_DB_PASSWORD: rec_password
      REC_DB_NAME: recommendation_db
      REDIS_HOST: redis
      REDIS_PORT: 6379
    depends_on:
      - recommendation_db
      - redis
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # --- Log Service ---
  log_service:
    build: ./log_service
    container_name: frontend_log_ingestion
    # ports:
    #   - "5006:5006"
    environment:
      KAFKA_BROKER_URL: kafka:29092  # 服务名通信
    depends_on:
      - kafka
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # --- MinIO Service ---
  minio:
    image: quay.io/minio/minio:RELEASE.2025-04-22T22-12-26Z
    container_name: minio
    # ports:
    #   - "9002:9000"
    #   - "9001:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_CORS_ALLOW_ORIGIN: "http://localhost:5173"
    volumes:
      - minio_data:/data
    command: minio server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9002/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

# 存储卷（通过kompose转换为K8s PVC）
volumes:
  auth_mysql_data:
  book_mongo_data:
  user_engagement_mysql_data:
  recommendation_mysql_data:
  clickhouse_data:
  clickhouse_logs:
  redis_data:
  minio_data: