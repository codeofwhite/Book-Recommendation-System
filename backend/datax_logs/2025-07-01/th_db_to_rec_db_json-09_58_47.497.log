2025-07-01 09:58:48.003 [main] INFO  MessageSource - JVM TimeZone: GMT+08:00, Locale: zh_CN
2025-07-01 09:58:48.007 [main] INFO  MessageSource - use Locale: zh_CN timeZone: sun.util.calendar.ZoneInfo[id="GMT+08:00",offset=28800000,dstSavings=0,useDaylight=false,transitions=0,lastRule=null]
2025-07-01 09:58:48.079 [main] INFO  VMInfo - VMInfo# operatingSystem class => com.sun.management.internal.OperatingSystemImpl
2025-07-01 09:58:48.087 [main] INFO  Engine - the machine info  => 

	osInfo:	Linux amd64 5.15.167.4-microsoft-standard-WSL2
	jvmInfo:	Oracle Corporation 11 11.0.16+8
	cpu num:	2

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[G1 Young Generation, G1 Old Generation]

	MEMORY_NAME                    | allocation_size                | init_size                      
	CodeHeap 'profiled nmethods'   | 117.22MB                       | 2.44MB                         
	G1 Old Gen                     | 1,024.00MB                     | 970.00MB                       
	G1 Survivor Space              | -0.00MB                        | 0.00MB                         
	CodeHeap 'non-profiled nmethods' | 117.22MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	Metaspace                      | -0.00MB                        | 0.00MB                         
	G1 Eden Space                  | -0.00MB                        | 54.00MB                        
	CodeHeap 'non-nmethods'        | 5.56MB                         | 2.44MB                         


2025-07-01 09:58:48.125 [main] INFO  Engine - 
{
	"setting":{
		"speed":{
			"channel":3
		},
		"errorLimit":{
			"record":0,
			"percentage":0.02
		}
	},
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"username":"auth_user",
					"password":"*************",
					"column":[
						"id",
						"username",
						"email",
						"password_hash",
						"avatar_url"
					],
					"splitPk":"id",
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://auth_db:3306/auth_db"
							],
							"table":[
								"users"
							]
						}
					]
				}
			},
			"writer":{
				"name":"mysqlwriter",
				"parameter":{
					"username":"rec_user",
					"password":"************",
					"column":[
						"id",
						"username",
						"email",
						"password_hash",
						"avatar_url"
					],
					"preSql":[
						"TRUNCATE TABLE users_snapshot;"
					],
					"session":[
						
					],
					"connection":[
						{
							"jdbcUrl":"jdbc:mysql://recommendation_db:3306/recommendation_db",
							"table":[
								"users_snapshot"
							]
						}
					]
				}
			}
		}
	]
}

2025-07-01 09:58:48.164 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false
2025-07-01 09:58:48.164 [main] INFO  JobContainer - DataX jobContainer starts job.
2025-07-01 09:58:48.166 [main] INFO  JobContainer - Set jobId = 0
2025-07-01 09:58:49.208 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://auth_db:3306/auth_db?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2025-07-01 09:58:49.295 [job-0] INFO  OriginalConfPretreatmentUtil - table:[users] has columns:[id,username,email,password_hash,avatar_url].
2025-07-01 09:58:49.764 [job-0] INFO  OriginalConfPretreatmentUtil - table:[users_snapshot] all columns:[
id,username,email,password_hash,avatar_url
].
2025-07-01 09:58:49.800 [job-0] INFO  OriginalConfPretreatmentUtil - Write data [
INSERT INTO %s (id,username,email,password_hash,avatar_url) VALUES(?,?,?,?,?)
], which jdbcUrl like:[jdbc:mysql://recommendation_db:3306/recommendation_db?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&rewriteBatchedStatements=true&tinyInt1isBit=false]
2025-07-01 09:58:49.801 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2025-07-01 09:58:49.802 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2025-07-01 09:58:49.802 [job-0] INFO  JobContainer - DataX Writer.Job [mysqlwriter] do prepare work .
2025-07-01 09:58:49.856 [job-0] INFO  CommonRdbmsWriter$Job - Begin to execute preSqls:[TRUNCATE TABLE users_snapshot;]. context info:jdbc:mysql://recommendation_db:3306/recommendation_db?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&rewriteBatchedStatements=true&tinyInt1isBit=false.
2025-07-01 09:58:49.922 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2025-07-01 09:58:49.923 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2025-07-01 09:58:49.957 [job-0] INFO  SingleTableSplitUtil - split pk [sql=SELECT MIN(id),MAX(id) FROM users] is running... 
2025-07-01 09:58:49.979 [job-0] INFO  SingleTableSplitUtil - After split(), allQuerySql=[
select id,username,email,password_hash,avatar_url from users  where  (1 <= id AND id <= 2) 
select id,username,email,password_hash,avatar_url from users  where  id IS NULL
].
2025-07-01 09:58:49.980 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [2] tasks.
2025-07-01 09:58:49.981 [job-0] INFO  JobContainer - DataX Writer.Job [mysqlwriter] splits to [2] tasks.
2025-07-01 09:58:50.017 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2025-07-01 09:58:50.021 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2025-07-01 09:58:50.023 [job-0] INFO  JobContainer - Running by standalone Mode.
2025-07-01 09:58:50.031 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [2] channels for [2] tasks.
2025-07-01 09:58:50.050 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2025-07-01 09:58:50.051 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2025-07-01 09:58:50.078 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2025-07-01 09:58:50.114 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[1] attemptCount[1] is started
2025-07-01 09:58:50.115 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select id,username,email,password_hash,avatar_url from users  where  (1 <= id AND id <= 2) 
] jdbcUrl:[jdbc:mysql://auth_db:3306/auth_db?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2025-07-01 09:58:50.116 [0-0-1-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select id,username,email,password_hash,avatar_url from users  where  id IS NULL
] jdbcUrl:[jdbc:mysql://auth_db:3306/auth_db?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2025-07-01 09:58:50.215 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select id,username,email,password_hash,avatar_url from users  where  (1 <= id AND id <= 2) 
] jdbcUrl:[jdbc:mysql://auth_db:3306/auth_db?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2025-07-01 09:58:50.239 [0-0-1-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select id,username,email,password_hash,avatar_url from users  where  id IS NULL
] jdbcUrl:[jdbc:mysql://auth_db:3306/auth_db?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2025-07-01 09:58:50.332 [0-0-0-writer] WARN  CommonRdbmsWriter$Task - 回滚此次写入, 采用每次写入一行方式提交. 因为:TIMESTAMP 类型转换错误：[{"byteSize":57,"rawData":"/uploads/avatars/e2aad2e3-c592-41b6-a3d3-6a582e35304d.jpg","type":5}]
2025-07-01 09:58:50.341 [0-0-0-writer] ERROR StdoutPluginCollector - 
java.sql.SQLException: TIMESTAMP 类型转换错误：[{"byteSize":57,"rawData":"/uploads/avatars/e2aad2e3-c592-41b6-a3d3-6a582e35304d.jpg","type":5}]
	at com.alibaba.datax.plugin.rdbms.writer.CommonRdbmsWriter$Task.fillPreparedStatementColumnType(CommonRdbmsWriter.java:502) ~[plugin-rdbms-util-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.plugin.rdbms.writer.CommonRdbmsWriter$Task.fillPreparedStatement(CommonRdbmsWriter.java:406) ~[plugin-rdbms-util-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.plugin.rdbms.writer.CommonRdbmsWriter$Task.doOneInsert(CommonRdbmsWriter.java:380) ~[plugin-rdbms-util-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.plugin.rdbms.writer.CommonRdbmsWriter$Task.doBatchInsert(CommonRdbmsWriter.java:362) ~[plugin-rdbms-util-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.plugin.rdbms.writer.CommonRdbmsWriter$Task.startWriteWithConnection(CommonRdbmsWriter.java:297) ~[plugin-rdbms-util-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.plugin.rdbms.writer.CommonRdbmsWriter$Task.startWrite(CommonRdbmsWriter.java:319) ~[plugin-rdbms-util-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.plugin.writer.mysqlwriter.MysqlWriter$Task.startWrite(MysqlWriter.java:78) ~[mysqlwriter-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.taskgroup.runner.WriterRunner.run(WriterRunner.java:56) ~[datax-core-0.0.1-SNAPSHOT.jar:na]
	at java.base/java.lang.Thread.run(Unknown Source) ~[na:na]
2025-07-01 09:58:50.353 [0-0-0-writer] ERROR StdoutPluginCollector - 脏数据: 
{"exception":"TIMESTAMP 类型转换错误：[{\"byteSize\":57,\"rawData\":\"/uploads/avatars/e2aad2e3-c592-41b6-a3d3-6a582e35304d.jpg\",\"type\":5}]","record":[{"byteSize":1,"index":0,"rawData":1,"type":3},{"byteSize":6,"index":1,"rawData":"123456","type":5},{"byteSize":16,"index":2,"rawData":"123456@gamil.com","type":5},{"byteSize":60,"index":3,"rawData":"$2b$13$FVTlSVqtY2edTk1x6FhGTu8KFj9vSQvrelewctVO2nygQl6lnSpUy","type":5},{"byteSize":57,"index":4,"rawData":"/uploads/avatars/e2aad2e3-c592-41b6-a3d3-6a582e35304d.jpg","type":5}],"type":"writer"}
2025-07-01 09:58:50.354 [0-0-0-writer] ERROR StdoutPluginCollector - 脏数据: 
{"exception":"TIMESTAMP 类型转换错误：[{\"byteSize\":31,\"rawData\":\"https://via.placeholder.com/150\",\"type\":5}]","record":[{"byteSize":1,"index":0,"rawData":2,"type":3},{"byteSize":7,"index":1,"rawData":"1234567","type":5},{"byteSize":17,"index":2,"rawData":"1234567@gamil.com","type":5},{"byteSize":60,"index":3,"rawData":"$2b$13$Yk5s6F9EetXth78QE2e6S.6LyhzDAlRAhj/MYSgndts9tpOVcxESC","type":5},{"byteSize":31,"index":4,"rawData":"https://via.placeholder.com/150","type":5}],"type":"writer"}
2025-07-01 09:58:50.419 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[343]ms
2025-07-01 09:58:50.419 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[1] is successed, used[330]ms
2025-07-01 09:58:50.420 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2025-07-01 09:58:58.231 [job-0] ERROR JobContainer - 运行scheduler 模式[standalone]出错.
2025-07-01 09:58:58.231 [job-0] ERROR JobContainer - Exception when job run
com.alibaba.datax.common.exception.DataXException: Code:[Framework-14], Description:[DataX传输脏数据超过用户预期，该错误通常是由于源端数据存在较多业务脏数据导致，请仔细检查DataX汇报的脏数据日志信息, 或者您可以适当调大脏数据阈值 .].  - 脏数据条数检查不通过，限制是[0]条，但实际上捕获了[2]条.
	at com.alibaba.datax.common.exception.DataXException.asDataXException(DataXException.java:30) ~[datax-common-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.util.ErrorRecordChecker.checkRecordLimit(ErrorRecordChecker.java:58) ~[datax-core-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.job.scheduler.AbstractScheduler.schedule(AbstractScheduler.java:89) ~[datax-core-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.job.JobContainer.schedule(JobContainer.java:535) ~[datax-core-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.job.JobContainer.start(JobContainer.java:119) ~[datax-core-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.Engine.start(Engine.java:86) ~[datax-core-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.Engine.entry(Engine.java:168) ~[datax-core-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.Engine.main(Engine.java:201) ~[datax-core-0.0.1-SNAPSHOT.jar:na]
2025-07-01 09:58:58.234 [job-0] INFO  StandAloneJobContainerCommunicator - Total 2 records, 256 bytes | Speed 256B/s, 2 records/s | Error 2 records, 256 bytes |  All Task WaitWriterTime 0.001s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2025-07-01 09:58:58.235 [job-0] ERROR Engine - 

经DataX智能分析,该任务最可能的错误原因是:
com.alibaba.datax.common.exception.DataXException: Code:[Framework-14], Description:[DataX传输脏数据超过用户预期，该错误通常是由于源端数据存在较多业务脏数据导致，请仔细检查DataX汇报的脏数据日志信息, 或者您可以适当调大脏数据阈值 .].  - 脏数据条数检查不通过，限制是[0]条，但实际上捕获了[2]条.
	at com.alibaba.datax.common.exception.DataXException.asDataXException(DataXException.java:30)
	at com.alibaba.datax.core.util.ErrorRecordChecker.checkRecordLimit(ErrorRecordChecker.java:58)
	at com.alibaba.datax.core.job.scheduler.AbstractScheduler.schedule(AbstractScheduler.java:89)
	at com.alibaba.datax.core.job.JobContainer.schedule(JobContainer.java:535)
	at com.alibaba.datax.core.job.JobContainer.start(JobContainer.java:119)
	at com.alibaba.datax.core.Engine.start(Engine.java:86)
	at com.alibaba.datax.core.Engine.entry(Engine.java:168)
	at com.alibaba.datax.core.Engine.main(Engine.java:201)

